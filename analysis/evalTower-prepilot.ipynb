{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### establish connection to mongo\n",
    "First thing you need to do is to establish an ssh tunnel (aka remote port forwarding) to the server, so that requests to the mongodb can be made \"as if\" the mongodb server is running on your local computer. Run this from the command line before you begin data analysis if you plan to fetch data from mongo:\n",
    "\n",
    "`ssh -fNL 27017:127.0.0.1:27017 USERNAME@cogtoolslab.org`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import urllib, io\n",
    "os.getcwd()\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"../utils\")\n",
    "sys.path.append(\"../analysis/utils\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "\n",
    "import pymongo as pm\n",
    "from collections import Counter\n",
    "import json\n",
    "import re\n",
    "import ast\n",
    "\n",
    "from PIL import Image, ImageOps, ImageDraw, ImageFont \n",
    "\n",
    "from io import BytesIO\n",
    "import base64\n",
    "\n",
    "import  matplotlib\n",
    "from matplotlib import pylab, mlab, pyplot\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize, getfigs\n",
    "plt = pyplot\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_context('talk')\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")\n",
    "\n",
    "# import drawing_utils as drawing\n",
    "# import importlib\n",
    "# import scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## directory & file hierarchy\n",
    "proj_dir = os.path.abspath('..')\n",
    "datavol_dir = os.path.join(proj_dir,'data')\n",
    "analysis_dir =  os.path.abspath('.')\n",
    "results_dir = os.path.join(proj_dir,'results')\n",
    "plot_dir = os.path.join(results_dir,'plots')\n",
    "csv_dir = os.path.join(results_dir,'csv')\n",
    "json_dir = os.path.join(results_dir,'json')\n",
    "exp_dir = os.path.abspath(os.path.join(proj_dir,'behavioral_experiments'))\n",
    "png_dir = os.path.abspath(os.path.join(datavol_dir,'png'))\n",
    "\n",
    "## add helpers to python path\n",
    "if os.path.join(proj_dir,'stimuli') not in sys.path:\n",
    "    sys.path.append(os.path.join(proj_dir,'stimuli'))\n",
    "    \n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "    \n",
    "if not os.path.exists(plot_dir):\n",
    "    os.makedirs(plot_dir)   \n",
    "    \n",
    "if not os.path.exists(csv_dir):\n",
    "    os.makedirs(csv_dir)       \n",
    "    \n",
    "## add helpers to python path\n",
    "if os.path.join(proj_dir,'utils') not in sys.path:\n",
    "    sys.path.append(os.path.join(proj_dir,'utils'))   \n",
    "\n",
    "def make_dir_if_not_exists(dir_name):   \n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "    return dir_name\n",
    "\n",
    "## create directories that don't already exist        \n",
    "result = [make_dir_if_not_exists(x) for x in [results_dir,plot_dir,csv_dir]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set vars \n",
    "auth = pd.read_csv(os.path.join(analysis_dir,'auth.txt'), header = None) # this auth.txt file contains the password for the sketchloop user\n",
    "pswd = auth.values[0][0]\n",
    "user = 'sketchloop'\n",
    "host = 'cogtoolslab.org'\n",
    "\n",
    "# have to fix this to be able to analyze from local\n",
    "import pymongo as pm\n",
    "conn = pm.MongoClient('mongodb://sketchloop:' + pswd + '@127.0.0.1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = conn['curiotower']\n",
    "coll = db['curiotower_curiodrop']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['image-button-response']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll.distinct('type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['testing-new-meta']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterationName = 'testing-new-meta'\n",
    "coll.distinct('iterationName')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### construct tidy dataframe with game data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = coll.find({\n",
    "            'iterationName':iterationName\n",
    "#             'prolificID': {'$exists' : True},\n",
    "#             'studyID': {'$exists' : True},\n",
    "#             'sessionID': {'$exists' : True},\n",
    "#             'eventType': 'rating-task'\n",
    "})\n",
    "df = pd.DataFrame(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 36)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['_id', 'type', 'iterationName', 'numTrials', 'condition', 'prompt',\n",
       "       'towerID', 'image_url', 'stim_version', 'games', 'trialNum',\n",
       "       'prolificID', 'studyID', 'sessionID', 'gameID', 'image_html',\n",
       "       'session_id', 'upper_bound', 'lower_bound', 'choices', 'button_html',\n",
       "       'message', 'stimulus_duration', 'trial_duration', 'trial_num',\n",
       "       'margin_vertical', 'margin_horizontal', 'response_ends_trial',\n",
       "       'reaction_time', 'button_pressed', 'startTrialTime', 'endTrialTime',\n",
       "       'trial_type', 'trial_index', 'time_elapsed', 'internal_node_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 36)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>type</th>\n",
       "      <th>iterationName</th>\n",
       "      <th>numTrials</th>\n",
       "      <th>condition</th>\n",
       "      <th>prompt</th>\n",
       "      <th>towerID</th>\n",
       "      <th>image_url</th>\n",
       "      <th>stim_version</th>\n",
       "      <th>games</th>\n",
       "      <th>...</th>\n",
       "      <th>margin_horizontal</th>\n",
       "      <th>response_ends_trial</th>\n",
       "      <th>reaction_time</th>\n",
       "      <th>button_pressed</th>\n",
       "      <th>startTrialTime</th>\n",
       "      <th>endTrialTime</th>\n",
       "      <th>trial_type</th>\n",
       "      <th>trial_index</th>\n",
       "      <th>time_elapsed</th>\n",
       "      <th>internal_node_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5fb829606ccd8973aec081f9</td>\n",
       "      <td>image-button-response</td>\n",
       "      <td>testing-new-meta</td>\n",
       "      <td>6</td>\n",
       "      <td>stable</td>\n",
       "      <td>How stable is this?</td>\n",
       "      <td>121119_08b</td>\n",
       "      <td>https://curiotower.s3.amazonaws.com/121119_08b...</td>\n",
       "      <td>curiodrop</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>8px</td>\n",
       "      <td>True</td>\n",
       "      <td>450.060</td>\n",
       "      <td>0</td>\n",
       "      <td>15675.225</td>\n",
       "      <td>1.605905e+12</td>\n",
       "      <td>image-button-response</td>\n",
       "      <td>1</td>\n",
       "      <td>15678</td>\n",
       "      <td>0.0-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5fb829656ccd8973aec081fa</td>\n",
       "      <td>image-button-response</td>\n",
       "      <td>testing-new-meta</td>\n",
       "      <td>6</td>\n",
       "      <td>stable</td>\n",
       "      <td>How stable is this?</td>\n",
       "      <td>121619_09</td>\n",
       "      <td>https://curiotower.s3.amazonaws.com/121619_09.png</td>\n",
       "      <td>curiodrop</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>8px</td>\n",
       "      <td>True</td>\n",
       "      <td>615.995</td>\n",
       "      <td>1</td>\n",
       "      <td>20648.870</td>\n",
       "      <td>1.605905e+12</td>\n",
       "      <td>image-button-response</td>\n",
       "      <td>2</td>\n",
       "      <td>20817</td>\n",
       "      <td>0.0-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5fb8296a6ccd8973aec081fb</td>\n",
       "      <td>image-button-response</td>\n",
       "      <td>testing-new-meta</td>\n",
       "      <td>6</td>\n",
       "      <td>stable</td>\n",
       "      <td>How stable is this?</td>\n",
       "      <td>121119_10b</td>\n",
       "      <td>https://curiotower.s3.amazonaws.com/121119_10b...</td>\n",
       "      <td>curiodrop</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>8px</td>\n",
       "      <td>True</td>\n",
       "      <td>457.750</td>\n",
       "      <td>2</td>\n",
       "      <td>25782.830</td>\n",
       "      <td>1.605905e+12</td>\n",
       "      <td>image-button-response</td>\n",
       "      <td>3</td>\n",
       "      <td>25793</td>\n",
       "      <td>0.0-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5fb8296f6ccd8973aec081fc</td>\n",
       "      <td>image-button-response</td>\n",
       "      <td>testing-new-meta</td>\n",
       "      <td>6</td>\n",
       "      <td>stable</td>\n",
       "      <td>How stable is this?</td>\n",
       "      <td>121119_09</td>\n",
       "      <td>https://curiotower.s3.amazonaws.com/121119_09.png</td>\n",
       "      <td>curiodrop</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>8px</td>\n",
       "      <td>True</td>\n",
       "      <td>511.045</td>\n",
       "      <td>4</td>\n",
       "      <td>30756.920</td>\n",
       "      <td>1.605905e+12</td>\n",
       "      <td>image-button-response</td>\n",
       "      <td>4</td>\n",
       "      <td>30821</td>\n",
       "      <td>0.0-4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5fb829746ccd8973aec081fd</td>\n",
       "      <td>image-button-response</td>\n",
       "      <td>testing-new-meta</td>\n",
       "      <td>6</td>\n",
       "      <td>stable</td>\n",
       "      <td>How stable is this?</td>\n",
       "      <td>121119_10</td>\n",
       "      <td>https://curiotower.s3.amazonaws.com/121119_10.png</td>\n",
       "      <td>curiodrop</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>8px</td>\n",
       "      <td>True</td>\n",
       "      <td>829.225</td>\n",
       "      <td>4</td>\n",
       "      <td>35782.680</td>\n",
       "      <td>1.605905e+12</td>\n",
       "      <td>image-button-response</td>\n",
       "      <td>5</td>\n",
       "      <td>36164</td>\n",
       "      <td>0.0-5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5fb829796ccd8973aec081fe</td>\n",
       "      <td>image-button-response</td>\n",
       "      <td>testing-new-meta</td>\n",
       "      <td>6</td>\n",
       "      <td>stable</td>\n",
       "      <td>How stable is this?</td>\n",
       "      <td>121619_05</td>\n",
       "      <td>https://curiotower.s3.amazonaws.com/121619_05.png</td>\n",
       "      <td>curiodrop</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>8px</td>\n",
       "      <td>True</td>\n",
       "      <td>535.050</td>\n",
       "      <td>4</td>\n",
       "      <td>41126.475</td>\n",
       "      <td>1.605905e+12</td>\n",
       "      <td>image-button-response</td>\n",
       "      <td>6</td>\n",
       "      <td>41214</td>\n",
       "      <td>0.0-6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5fb8297f6ccd8973aec081ff</td>\n",
       "      <td>image-button-response</td>\n",
       "      <td>testing-new-meta</td>\n",
       "      <td>6</td>\n",
       "      <td>stable</td>\n",
       "      <td>How stable is this?</td>\n",
       "      <td>121619_08b</td>\n",
       "      <td>https://curiotower.s3.amazonaws.com/121619_08b...</td>\n",
       "      <td>curiodrop</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>8px</td>\n",
       "      <td>True</td>\n",
       "      <td>624.270</td>\n",
       "      <td>4</td>\n",
       "      <td>46178.205</td>\n",
       "      <td>1.605905e+12</td>\n",
       "      <td>image-button-response</td>\n",
       "      <td>7</td>\n",
       "      <td>46355</td>\n",
       "      <td>0.0-7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id                   type     iterationName  \\\n",
       "0  5fb829606ccd8973aec081f9  image-button-response  testing-new-meta   \n",
       "1  5fb829656ccd8973aec081fa  image-button-response  testing-new-meta   \n",
       "2  5fb8296a6ccd8973aec081fb  image-button-response  testing-new-meta   \n",
       "3  5fb8296f6ccd8973aec081fc  image-button-response  testing-new-meta   \n",
       "4  5fb829746ccd8973aec081fd  image-button-response  testing-new-meta   \n",
       "5  5fb829796ccd8973aec081fe  image-button-response  testing-new-meta   \n",
       "6  5fb8297f6ccd8973aec081ff  image-button-response  testing-new-meta   \n",
       "\n",
       "   numTrials condition               prompt     towerID  \\\n",
       "0          6    stable  How stable is this?  121119_08b   \n",
       "1          6    stable  How stable is this?   121619_09   \n",
       "2          6    stable  How stable is this?  121119_10b   \n",
       "3          6    stable  How stable is this?   121119_09   \n",
       "4          6    stable  How stable is this?   121119_10   \n",
       "5          6    stable  How stable is this?   121619_05   \n",
       "6          6    stable  How stable is this?  121619_08b   \n",
       "\n",
       "                                           image_url stim_version games  ...  \\\n",
       "0  https://curiotower.s3.amazonaws.com/121119_08b...    curiodrop    []  ...   \n",
       "1  https://curiotower.s3.amazonaws.com/121619_09.png    curiodrop    []  ...   \n",
       "2  https://curiotower.s3.amazonaws.com/121119_10b...    curiodrop    []  ...   \n",
       "3  https://curiotower.s3.amazonaws.com/121119_09.png    curiodrop    []  ...   \n",
       "4  https://curiotower.s3.amazonaws.com/121119_10.png    curiodrop    []  ...   \n",
       "5  https://curiotower.s3.amazonaws.com/121619_05.png    curiodrop    []  ...   \n",
       "6  https://curiotower.s3.amazonaws.com/121619_08b...    curiodrop    []  ...   \n",
       "\n",
       "   margin_horizontal response_ends_trial reaction_time button_pressed  \\\n",
       "0                8px                True       450.060              0   \n",
       "1                8px                True       615.995              1   \n",
       "2                8px                True       457.750              2   \n",
       "3                8px                True       511.045              4   \n",
       "4                8px                True       829.225              4   \n",
       "5                8px                True       535.050              4   \n",
       "6                8px                True       624.270              4   \n",
       "\n",
       "  startTrialTime  endTrialTime             trial_type trial_index  \\\n",
       "0      15675.225  1.605905e+12  image-button-response           1   \n",
       "1      20648.870  1.605905e+12  image-button-response           2   \n",
       "2      25782.830  1.605905e+12  image-button-response           3   \n",
       "3      30756.920  1.605905e+12  image-button-response           4   \n",
       "4      35782.680  1.605905e+12  image-button-response           5   \n",
       "5      41126.475  1.605905e+12  image-button-response           6   \n",
       "6      46178.205  1.605905e+12  image-button-response           7   \n",
       "\n",
       "  time_elapsed internal_node_id  \n",
       "0        15678          0.0-1.0  \n",
       "1        20817          0.0-2.0  \n",
       "2        25793          0.0-3.0  \n",
       "3        30821          0.0-4.0  \n",
       "4        36164          0.0-5.0  \n",
       "5        41214          0.0-6.0  \n",
       "6        46355          0.0-7.0  \n",
       "\n",
       "[7 rows x 36 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['button_pressed'] = pd.to_numeric(df['button_pressed'])\n",
    "print(df.shape)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['button_pressed'].hist(bins = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _______________________________________________________\n",
    "\n",
    "# After this point is old compabs analysis (saving just in case...)\n",
    "\n",
    "\n",
    "# ________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## get list of all gameIDs in database\n",
    "total_games = coll.find({'iterationName':iterationName}).distinct('gameid')\n",
    "print('There are {} total games.'.format(len(total_games)))\n",
    "\n",
    "## get list of complete gameIDs\n",
    "gameIDs = coll.find({'iterationName':iterationName}).distinct('gameid')\n",
    "complete_games = [g for g in gameIDs if len(coll.find({'gameid':g}).distinct('trialNum')) == numTrials]\n",
    "print('There are {} complete games.'.format(len(complete_games)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "broken_games = []\n",
    "complete_games = [g for g in complete_games if g not in broken_games]\n",
    "\n",
    "def construct_tidy_dataframe(eventType = 'chatMessage', \n",
    "                             complete_games = [],\n",
    "                             iterationName = 'pilot1',\n",
    "                             remove_workerID = True):\n",
    "    '''\n",
    "    input: list of complete games and name of event Type\n",
    "    '''\n",
    "    event2name = {'chatMessage':'chat', 'block':'block', 'endTrial':'trial', 'exitSurvey':'exit'}\n",
    "    L = pd.DataFrame()\n",
    "    for g, this_gameID in enumerate(complete_games):\n",
    "        print('Analyzing game {} | {} of {}'.format(this_gameID, g+1, len(complete_games)))\n",
    "        clear_output(wait=True) \n",
    "\n",
    "        ### extract records \n",
    "        #loop over iteration names??\n",
    "        X = coll.find({ '$and': [{'iterationName':iterationName}, \n",
    "#                                  {\"$or\":[{'iterationName':'Exp2Pilot3'},\n",
    "#                                  {'iterationName':'Exp2Pilot3_batch2'}]}\n",
    "                                 {'gameid': this_gameID}, {'eventType': eventType}]}).sort('time') \n",
    "        \n",
    "        li = list(X)        \n",
    "        _L = pd.DataFrame(li)  \n",
    "\n",
    "        ## concat with previous game's dataframe\n",
    "        if L.shape[0]==0:\n",
    "            L = _L\n",
    "        else: \n",
    "            L = pd.concat([L,_L], axis=0)     \n",
    "\n",
    "    ## postprocessing\n",
    "    if remove_workerID and 'workerId' in L.columns:\n",
    "        L = L.drop('workerId',axis=1)\n",
    "\n",
    "    ## save out group dataframe to csv dir\n",
    "    out_path = os.path.join(csv_dir,'compabs_{}_{}.csv'.format(event2name[eventType],iterationName))\n",
    "    print('Saving dataframe out to CSV dir at path: {}'.format(out_path))    \n",
    "    L.to_csv(out_path)             \n",
    "\n",
    "    return L\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## construct dataframe for each datatype\n",
    "dataTypes = coll.distinct('eventType')\n",
    "for thisDataType in dataTypes:\n",
    "    X = construct_tidy_dataframe(eventType=thisDataType, complete_games=complete_games, iterationName=iterationName)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full DF from DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure one to one gameID and workerId \n",
    "# Should only happen if a repeat worker gets through\n",
    "\n",
    "# query = coll.find({\"$and\":[\n",
    "# #                         {'workerId':{'$exists':True}},\n",
    "# #                         {'condition':{'$ne':'practice'}},\n",
    "# #                         {'eventType':'trial_end'},\n",
    "#                         {\"$or\":[{'iterationName':'testing'}]}]\n",
    "#                      })\n",
    "\n",
    "#df_trial_end_full = pd.DataFrame(list(query.sort('timeAbsolute')))\n",
    "#df_trial_end_full[['workerId','gameID']]\n",
    "\n",
    "query = coll.find()\n",
    "\n",
    "df_trial_end_full = pd.DataFrame(list(query))\n",
    "\n",
    "#assert (np.mean(df_trial_end_full['workerId'].value_counts()) == np.mean(df_trial_end_full['gameID'].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## How many records?\n",
    "coll.estimated_document_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_trial_end_full.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check outcome for specific workerID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set worker ID\n",
    "workerID = 'A37XBH865833FE'\n",
    "iteration = 'pilot0'\n",
    "#get GameID (not all info available at workerID level (e.g. bonus))\n",
    "gameID = df_trial_end_full[df_trial_end_full['workerId'] == workerID]['gameid'].unique()[0]\n",
    "\n",
    "#check iteration name\n",
    "df_game = df_trial_end_full[(df_trial_end_full['iterationName'] == iteration) &\n",
    "                            (df_trial_end_full['gameid'] == gameID)]\n",
    "#get workerIds\n",
    "print('workerIDS:',df_game['workerId'].unique())\n",
    "#get bonus for gameID ([air of workerIDs])\n",
    "print(\"Bonus:\",np.nanmax(df_game['cumulativeBonus']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trial_end_full[(df_trial_end_full['iterationName'] == 'pilot2')].content.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see full history for single worker\n",
    "df_test = df_trial_end_full[(df_trial_end_full['iterationName'] == iterationName)&\n",
    "                           (df_trial_end_full['workerId'] == workerID)]\n",
    "df_test.content.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial Level Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming that if trial 23 saves, then 0-22 have also saved \n",
    "# # get ids of people with trial 23 data\n",
    "# query = coll.find({\"$and\":[\n",
    "#                         {'condition':{'$ne':'practice'}},\n",
    "#                         {'eventType':'trial_end'},\n",
    "#                         {\"$or\":[{'iterationName':'Exp2Pilot3'},\n",
    "#                                 {'iterationName':'Exp2Pilot3_batch2'}]},\n",
    "#                         #{'iterationName': iterationName}, #use this if one iteration name\n",
    "#                         {'trialNum': numTrials-1}]\n",
    "#                      })\n",
    "# complete_data_df = pd.DataFrame(query)\n",
    "# complete_data_ids = list(complete_data_df['workerId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Filter for full datasets\n",
    "# query = coll.find({\"$and\":[\n",
    "#                         {'condition':{'$ne':'practice'}},\n",
    "#                         {'eventType':'trial_end'},\n",
    "#                         #{'iterationName': iterationName}, #use this if one iteration name\n",
    "#                         {\"$or\":[{'iterationName':'Exp2Pilot3'},\n",
    "#                                 {'iterationName':'Exp2Pilot3_batch2'}]}]\n",
    "#                      })\n",
    "\n",
    "# df_trial_end_full = pd.DataFrame(list(query.sort('timeAbsolute')))\n",
    "\n",
    "\n",
    "# # filter dataframe for complete datasets\n",
    "# df_trial_end_full_filtered = df_trial_end_full[df_trial_end_full.workerId.isin(complete_data_ids)]\n",
    "\n",
    "# # reduce to crucial information\n",
    "# df_trial_end_reduced_filtered = df_trial_end_full_filtered[[\n",
    "#     'gameID','trialNum','phase','condition','eventType','targetName','repetition','targetID', #trial identifiers\n",
    "#     'nullScore','F1Score','normedScore','rawScoreDiscrete','nullScoreDiscrete','normedScoreDiscrete','scoreGapDiscrete', #scoring\n",
    "#     'numBlocks','nPracticeAttempts','blockColor','blockColorID','blockFell','doNothingRepeats',#misc. trial info\n",
    "#     'score','currBonus','timeBonus', #bonusing\n",
    "#     'timeAbsolute','timeRelative','buildTime','buildStartTime','buildFinishTime','timeToBuild', #timing \n",
    "#     'discreteWorld','allVertices', #world reconstruction\n",
    "#     'browser','browserVersion','os','devMode', #developer info\n",
    "#     #below here should be the same for every trial in a dataset\n",
    "#     'iterationName',\n",
    "#     'numTargets', 'prePostSetSize','numRepetitions', #pre-post info\n",
    "#     'bonusThresholdLow','bonusThresholdMid','bonusThresholdHigh','timeThresholdYellow','timeThresholdRed', #bonus info\n",
    "#     ]]\n",
    "\n",
    "# #Fix error in data-saving- normedScoreDiscrete saved as rawScoreDiscrete\n",
    "# df_trial_end_reduced_filtered['normedScoreDiscrete'] = df_trial_end_reduced_filtered['rawScoreDiscrete']\n",
    "# df_trial_end_reduced_filtered.drop(['rawScoreDiscrete'], axis=1)\n",
    "\n",
    "\n",
    "# df = df_trial_end_reduced_filtered.sort_values(by=['gameID', 'timeAbsolute'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DF for each event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in dataframes from each eventType\n",
    "df_block = pd.read_csv('../results/csv/compabs_block_{}.csv'.format(iterationName))\n",
    "df_chat = pd.read_csv('../results/csv/compabs_chat_{}.csv'.format(iterationName))\n",
    "df_exit = pd.read_csv('../results/csv/compabs_exit_{}.csv'.format(iterationName))\n",
    "df_trial = pd.read_csv('../results/csv/compabs_trial_{}.csv'.format(iterationName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manually build full df (needs to be generalized)\n",
    "df_block0 = pd.read_csv('../results/csv/compabs_block_{}.csv'.format('pilot0'))\n",
    "df_chat0 = pd.read_csv('../results/csv/compabs_chat_{}.csv'.format('pilot0'))\n",
    "df_exit0 = pd.read_csv('../results/csv/compabs_exit_{}.csv'.format('pilot0'))\n",
    "df_trial0 = pd.read_csv('../results/csv/compabs_trial_{}.csv'.format('pilot0'))\n",
    "#\n",
    "df_block1 = pd.read_csv('../results/csv/compabs_block_{}.csv'.format('pilot1'))\n",
    "df_chat1 = pd.read_csv('../results/csv/compabs_chat_{}.csv'.format('pilot1'))\n",
    "df_exit1 = pd.read_csv('../results/csv/compabs_exit_{}.csv'.format('pilot1'))\n",
    "df_trial1 = pd.read_csv('../results/csv/compabs_trial_{}.csv'.format('pilot1'))\n",
    "#\n",
    "df_block2 = pd.read_csv('../results/csv/compabs_block_{}.csv'.format('pilot2'))\n",
    "df_chat2 = pd.read_csv('../results/csv/compabs_chat_{}.csv'.format('pilot2'))\n",
    "df_exit2 = pd.read_csv('../results/csv/compabs_exit_{}.csv'.format('pilot2'))\n",
    "df_trial2 = pd.read_csv('../results/csv/compabs_trial_{}.csv'.format('pilot2'))\n",
    "\n",
    "df_block = pd.concat([df_block0,df_block1,df_block2])\n",
    "df_chat = pd.concat([df_chat0,df_chat1,df_chat2])\n",
    "df_exit = pd.concat([df_exit0,df_exit1,df_exit2])\n",
    "df_trial = pd.concat([df_trial0,df_trial1,df_trial2])\n",
    "\n",
    "print(\"Total Completed Games:\",len(df_exit.gameid.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exclusion Criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many dyads fulfill 75% Accuracy on 75% of trials\n",
    "df75 = pd.DataFrame(df_trial.groupby(['gameid', 'trialNum'])['trialScore'].sum()>75).groupby(['gameid']).sum()\n",
    "df75['trials'] = df75['trialScore']\n",
    "print(\"Total dyads achieving 75% Accuracy on 75% of trials:\",len(df75[df75['trials']>=9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exit.confused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in dataframes from each eventType\n",
    "# block_data = []\n",
    "# for i in range(0,3):\n",
    "#     block_data.append(pd.read_csv('../results/csv/compabs_block_pilot{}.csv'.format(i)))\n",
    "# df_block = pd.concat(block_data)\n",
    "# df_block =  [pd.merge(pd.read_csv('../results/csv/compabs_block_pilot{}.csv'.format(i))) for i in range(0,3)]\n",
    "# df_chat = pd.read_csv('../results/csv/compabs_chat_{}.csv'.format(iterationName))\n",
    "# df_exit = pd.read_csv('../results/csv/compabs_exit_{}.csv'.format(iterationName))\n",
    "# df_trial = pd.read_csv('../results/csv/compabs_trial_{}.csv'.format(iterationName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_block.iterationName.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exit.comments.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total Game Duration (for Gameplay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_exit.groupby(['gameid'])['totalLength'].max()/60000).hist()\n",
    "plt.xlabel(\"Duration (min)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_exit.groupby(['gameid'])['totalLength'].max()/60000).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect some raw data: language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create columns for char and word counts\n",
    "df_chat['word_count'] = df_chat['content'].str.split(' ').str.len()\n",
    "df_chat['char_count'] = df_chat['content'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coerce trialNum to numeric -- will remove \"practice\". Thoughts?\n",
    "df_chat['trialNum'] = pd.to_numeric(df_chat['trialNum'], errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspect specific chat history of one dyad\n",
    "dyadGameId = '8548-343a533f-0369-4b20-bbd4-a00f25359cea'\n",
    "df_chat[(df_chat.gameid == dyadGameId)]['content'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect some raw data: display block towers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(drawing)\n",
    "df_block['w'] = df_block['width']\n",
    "df_block['h'] = df_block['height']\n",
    "floatCols = ['w','h','blockNum','turnNum','x','y']\n",
    "df_block[floatCols] = df_block[floatCols].applymap(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "drawing.draw_from_actions_subplot(df_block[(df_block.leftTarget == 'C') & \n",
    "                                           (df_block.rightTarget == 'Pi') &\n",
    "                                           (df_block.gameid == '0662-7a9212c9-5aa7-44de-9ed7-4663c56562d2')], \n",
    "                                  ax, \n",
    "                                  world_size = [12,8])\n",
    "plt.title(\"Block Heat Map for 'C, Pi'\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make basic visualizations and calculate descriptives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architect: mean number of words across trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get sum of words for each trial, group by game then average across games\n",
    "print(df_chat.groupby(['gameid','trialNum'])['word_count'].sum().groupby(['trialNum']).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "df_chat.groupby(['gameid','trialNum'])['word_count'].sum().groupby(['trialNum']).mean().plot(ax = ax)\n",
    "plt.ylabel('Word Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "mean = df_chat.groupby(['gameid','trialNum'])['word_count'].sum().groupby(['trialNum']).mean()\n",
    "std = df_chat.groupby(['gameid','trialNum'])['word_count'].sum().groupby(['trialNum']).std()\n",
    "\n",
    "plt.errorbar(mean.index, mean, yerr=2*std, linestyle='--')\n",
    "plt.ylabel('Word Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## print summary stat to console?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Architect: mean number of characters across trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "df_chat.groupby(['gameid','trialNum'])['char_count'].sum().groupby(['trialNum']).mean().plot(ax = ax)\n",
    "plt.ylabel('Char Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architect: mean number of messages (across turns within a trial) across trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "df_chat.groupby(['gameid','trialNum'])['_id'].count().groupby(['trialNum']).mean().plot(ax = ax)\n",
    "plt.ylabel('Messages per trial')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architect: Total typing time (across turns within at trial) across trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check time elapsed\n",
    "df_chat[\"timeElapsedInTurn\"] = pd.to_numeric(df_chat['timeElapsedInTurn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## line plots\n",
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "df_chat.groupby(['gameid','trialNum'])['timeElapsedInTurn'].sum().groupby(['trialNum']).mean().plot(ax = ax)\n",
    "plt.ylabel('Average Time elapsed, Architect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chat.groupby(['gameid','trialNum'])['timeElapsedInTurn'].sum().groupby(['trialNum']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Builder: Reconstruction accuracy (intersection over union, IOU) across trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coerce trialNum to numeric -- will remove \"practice\". Thoughts?\n",
    "df_trial['trialNum'] = pd.to_numeric(df_trial['trialNum'], errors = 'coerce')\n",
    "#Coerce trialNum to numeric -- will remove \"practice\". Thoughts?\n",
    "df_block['trialNum'] = pd.to_numeric(df_block['trialNum'], errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "df_trial.groupby(['trialNum','gameid'])['trialScore'].sum().groupby(['trialNum']).mean().plot(ax = ax)\n",
    "plt.ylabel('Trial Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "df_trial.groupby(['trialNum','gameid'])['trialScore'].sum().unstack().plot(ax = ax)\n",
    "ax.get_legend().remove()\n",
    "plt.ylabel('Trial Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "df_trial.groupby(['repNum','gameid'])['trialScore'].mean().unstack().plot(ax = ax)\n",
    "ax.get_legend().remove()\n",
    "plt.ylabel('Trial Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trial.groupby(['gameid'])['trialScore'].mean().hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dist of trial scores:\n",
    "(df_trial.groupby(['gameid','trialNum']).trialScore.max().hist(bins = 8))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 4000\n",
    "df_trial.groupby(['gameid','trialNum']).trialScore.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df_trial[df_trial.trialNum>=0].groupby(['gameid']).trialScore.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architect: Distribution of words over trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Builder: Distribution of blocks placed per utterance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_block.groupby(['gameid','trialNum', 'turnNum'])['_id'].count()).hist(bins = 8)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Builder: Total reconstruction time (summed build time across turns, within each trial) across trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check time elapsed\n",
    "df_block[\"timeElapsedInTurn\"] = pd.to_numeric(df_block['timeElapsedInTurn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_block.groupby(['gameid','trialNum'])['timeElapsedInTurn'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## line plots\n",
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "df_block.groupby(['gameid','trialNum'])['timeElapsedInTurn'].sum().groupby(['trialNum']).mean().plot(ax = ax)\n",
    "plt.ylabel('Average Time elapsed, Builder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## line plots: time for each builder\n",
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "df_block.groupby(['trialNum','gameid'])['timeElapsedInTurn'].sum().unstack().plot(ax = ax)\n",
    "ax.get_legend().remove()\n",
    "plt.ylabel('Time elapsed in trial Builder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_block.timeElapsedInTurn.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's look at the DVs above, w.r.t. repetition of scenes, IGNORING which side a tower appears on... so across four repetitions (where [A,B] is equivalent to [B,A])\n",
    "\n",
    "#### use rep num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def convert(list): \n",
    "    return tuple(i for i in list)\n",
    "df_chat['targetSet'] = convert(df_chat[['leftTarget', 'rightTarget']].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chat.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "df_chat.groupby(['gameid','targetSet'])['word_count'].sum().groupby(['targetSet']).mean().plot.bar(ax = ax)\n",
    "plt.ylabel('Words Per figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
